{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==2.4.0\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-geometric\n",
        "!pip install optuna\n",
        "!pip install numpy-indexed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGXp36IT3850",
        "outputId": "042413a6-6ea7-47fc-c7d1-e2a0b9cacb0c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Collecting torch==2.4.0\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/pyg_lib-0.4.0%2Bpt24cu121-cp311-cp311-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp311-cp311-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_sparse-0.6.18%2Bpt24cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_cluster-1.6.3%2Bpt24cu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt24cu121-cp311-cp311-linux_x86_64.whl (989 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.8/989.8 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt24cu121 torch_cluster-1.6.3+pt24cu121 torch_scatter-2.1.2+pt24cu121 torch_sparse-0.6.18+pt24cu121 torch_spline_conv-1.2.2+pt24cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n",
            "Collecting numpy-indexed\n",
            "  Downloading numpy_indexed-0.3.7-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from numpy-indexed) (2.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from numpy-indexed) (1.0.0)\n",
            "Downloading numpy_indexed-0.3.7-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: numpy-indexed\n",
            "Successfully installed numpy-indexed-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, GATv2Conv\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool\n",
        "from torch_geometric.nn import aggr\n",
        "from torch_geometric.nn.norm import GraphNorm, LayerNorm, BatchNorm\n",
        "import torch_geometric\n",
        "\n",
        "import seaborn\n",
        "import optuna\n",
        "import h5py\n",
        "import numpy_indexed as npi\n",
        "import random\n",
        "\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "oVD9Wtxi5NLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj-0U9IO36Dn",
        "outputId": "16535c84-a485-4d93-ad02-2c9bad1fda15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdbs_paths = sorted(glob.glob('/content/drive/MyDrive/gpcrpeptidedesign/orphanpreprocessing/jan29relaxed*.parquet'))"
      ],
      "metadata": {
        "id": "KgQDMynw7rVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcrs = []\n",
        "peptides = []\n",
        "plddts = []\n",
        "paths = []\n",
        "plddt_peptides = []\n",
        "plddt_gpcrs = []\n",
        "plddt_atoms = []\n",
        "\n",
        "# Dictionary to store PDB data\n",
        "pdb_frames = dict()\n",
        "for pdbs in pdbs_paths:\n",
        "    print(pdbs)\n",
        "    pdbs = pd.read_parquet(pdbs)\n",
        "    for key, st in pdbs.groupby('path'):\n",
        "        if 'amber_r_' in key:\n",
        "            original_key = key\n",
        "            key = key.replace('amber_r_', '')\n",
        "        gpcrs.append(key.split('/')[-1].split('_')[0])\n",
        "        peptides.append(key.split('/')[-1].split('_')[1])\n",
        "        plddt_peptides.append(st[st['chain_id'] == 'B'].groupby('residue_seq_id')['b_factor'].first().mean())\n",
        "        plddt_gpcrs.append(st[st['chain_id'] == 'A'].groupby('residue_seq_id')['b_factor'].first().mean())\n",
        "        plddt_atoms.append(st[st['chain_id'] == 'B']['b_factor'].mean())\n",
        "        paths.append(original_key)\n",
        "        pdb_frames[original_key] = st\n",
        "    del pdbs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEnJ2-Ba7yK9",
        "outputId": "96a353be-47f1-4c00-bfb5-5b1f2e9ef1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/gpcrpeptidedesign/orphanpreprocessing/jan29relaxedpdbs_0.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orphandatalabels = pd.read_csv('/content/drive/MyDrive/gpcrpeptidedesign/non-dataset_worm_LABELS.csv')"
      ],
      "metadata": {
        "id": "7qGgh7SX8HpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orphandata = pd.read_csv('/content/drive/MyDrive/gpcrpeptidedesign/non-dataset_worm_plddt_iptm_activebias.csv')"
      ],
      "metadata": {
        "id": "UDspjCEq0pS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st = pd.DataFrame({'path': paths, 'gpcr': gpcrs, 'peptide': peptides, 'plddt_peptides': plddt_peptides, 'plddt_gpcrs': plddt_gpcrs, 'plddt_atoms': plddt_atoms})\n",
        "merged = pd.merge(orphandata, st, how='left', left_on=['GPCR', 'Peptide'], right_on=['gpcr', 'peptide'])\n",
        "merged['gpcr_family'] = merged['GPCR'].str[:-2]"
      ],
      "metadata": {
        "id": "QKTYxA6S0tHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged = pd.merge(merged, orphandatalabels, how='left', left_on=['GPCR', 'Peptide'], right_on=['GPCR', 'Peptide'])\n",
        "merged['y'] = merged['binds'].fillna(False).astype(int)"
      ],
      "metadata": {
        "id": "43BhN_a18VBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8705ab1c-fcc4-4988-decc-a85e48656d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-7a775d7d7c82>:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  merged['y'] = merged['binds'].fillna(False).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpcr_hits = merged[merged['gpcr'].isna() == False]\n",
        "gpcrs_lens = []\n",
        "peps_lens = []\n",
        "for index, st in gpcr_hits.iterrows():\n",
        "    pdb = pdb_frames[st['path']]\n",
        "    rec = pdb[pdb['chain_id'] == 'A']\n",
        "    pep = pdb[pdb['chain_id'] == 'B']\n",
        "    gpcrs_lens.append(rec['residue_seq_id'].max())\n",
        "    peps_lens.append(pep['residue_seq_id'].max())\n",
        "gpcr_hits['gpcr_len'] = gpcrs_lens\n",
        "gpcr_hits['pep_len'] = peps_lens"
      ],
      "metadata": {
        "id": "BBwLJ9XC9EPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contact_paths = glob.glob('/content/drive/MyDrive/gpcrpeptidedesign/november28/nov28contacts_*.parquet')\n",
        "allcontacts = []\n",
        "for cpath in contact_paths:\n",
        "    allcontacts.append(pd.read_parquet(cpath))\n",
        "allcontacts = pd.concat(allcontacts)\n",
        "total_interactions = allcontacts.groupby('path')['path'].count()\n",
        "total_interactions = pd.DataFrame(total_interactions)\n",
        "total_interactions.columns = ['total_interactions']\n",
        "gpcr_hits_bonds = pd.merge(gpcr_hits, total_interactions, how='left', on='path')"
      ],
      "metadata": {
        "id": "oSC4j_EqO2tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions = dict()\n",
        "for key, st in allcontacts.groupby('path'):\n",
        "    interactions[key] = st"
      ],
      "metadata": {
        "id": "mx6C-j6TPGoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bond_type_array = []\n",
        "for index, st in gpcr_hits.iterrows():\n",
        "    pdb = pdb_frames[st['path']]\n",
        "    bond_type_mapping = defaultdict(int)\n",
        "    if st['path'] in interactions:\n",
        "        bond = interactions[st['path']]\n",
        "        for other_index, b in bond.iterrows():\n",
        "            for bond_type in b['contact']:\n",
        "                bond_type_mapping[bond_type] += 1\n",
        "\n",
        "    bond_type_mapping['path'] = st['path']\n",
        "    bond_type_array.append(bond_type_mapping)"
      ],
      "metadata": {
        "id": "PWQquwPoPTNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bond_st = pd.DataFrame(bond_type_array)\n",
        "important_bonds = ['hydrophobic', 'polar', 'weak_polar', 'hbond', 'weak_hbond', 'ionic', 'aromatic', 'CARBONPI', 'vdw', 'vdw_clash', 'AMIDERING', 'AMIDEAMIDE', 'CATIONPI', 'METSULPHURPI']\n",
        "bond_st = bond_st[important_bonds+['path']].fillna(0)"
      ],
      "metadata": {
        "id": "ixvM0UK0Pc5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcr_hits_bonds = pd.merge(gpcr_hits_bonds, bond_st, how='left', on='path')"
      ],
      "metadata": {
        "id": "4dNrrrQdPfnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcr_hits = gpcr_hits_bonds.copy()"
      ],
      "metadata": {
        "id": "By9L0lESPmAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcr_hits['GPCR name'] = gpcr_hits['GPCR']"
      ],
      "metadata": {
        "id": "vvW6daxI6Col"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lens = gpcr_hits.groupby(['GPCR name'])['gpcr_len'].first()"
      ],
      "metadata": {
        "id": "hCORmMqyPwV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcr_hits_interaction_edges = dict()\n",
        "for index, g in gpcr_hits.iterrows():\n",
        "    pdb = pdb_frames[g['path']].copy()\n",
        "    if g['path'] not in interactions:\n",
        "        continue\n",
        "    bonds = interactions[g['path']]\n",
        "\n",
        "    gpcr_len = g['gpcr_len']\n",
        "\n",
        "    bonds['source'] = bonds['bgn'].apply(lambda x: x['auth_seq_id'] if x['auth_asym_id'] == \"A\" else x['auth_seq_id'] + gpcr_len) - 1\n",
        "    bonds['target'] = bonds['end'].apply(lambda x: x['auth_seq_id'] if x['auth_asym_id'] == \"A\" else x['auth_seq_id'] + gpcr_len) - 1\n",
        "    bonds = bonds.groupby(['source', 'target'])['contact'].agg(lambda x: {bondtype for array in x for bondtype in array}).reset_index()\n",
        "    sources = bonds['source'].values\n",
        "    targets = bonds['target'].values\n",
        "\n",
        "    h_edge_index = np.vstack([sources,targets])\n",
        "    key = g['gpcr']+'_'+g['peptide']\n",
        "    gpcr_hits_interaction_edges[key] = h_edge_index"
      ],
      "metadata": {
        "id": "C59sqHnRPz0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdfs = sorted(glob.glob('/content/drive/MyDrive/peptide/ReP-Pair/AF2/multistate_embeddings/worm_orphans/activebias_pair_representations/average_of_5_models/interaction_region_avg/*.h5'))"
      ],
      "metadata": {
        "id": "PoB8vkCJP2Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_map_interaction = dict()\n",
        "emb_map_interaction_gpcrindex = dict()\n",
        "pairmissed = []\n",
        "for hdf in hdfs:\n",
        "    with h5py.File(hdf, \"r\") as f:\n",
        "        keys = list(f.keys())\n",
        "        gpcr = keys[0].split('_')[0]\n",
        "        for k in keys:\n",
        "            try:\n",
        "                array = np.nan_to_num(f[k][()],0)\n",
        "                peptide = k.split('_')[1]\n",
        "                mapkey = gpcr+'_'+peptide\n",
        "                indices_to_keep = set()\n",
        "                maximum = lens[gpcr]\n",
        "                indices_to_keep.update(set(gpcr_hits_interaction_edges[mapkey][0]))\n",
        "                indices_to_keep.update(set(gpcr_hits_interaction_edges[mapkey][1]))\n",
        "                indices_to_keep = sorted([i for i in indices_to_keep if i < maximum])\n",
        "                emb_map_interaction[mapkey] = array[:,indices_to_keep,:]\n",
        "                emb_map_interaction_gpcrindex[mapkey] = np.array(indices_to_keep)\n",
        "            except:\n",
        "                pairmissed.append(k)\n",
        "                continue\n"
      ],
      "metadata": {
        "id": "RpehiC5SP7ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdfs2 = glob.glob('/content/drive/MyDrive/peptide/ReP-Pair/AF2/multistate_embeddings/worm_orphans/activebias_pair_representations/average_of_5_models/2D_t-average/*.h5')"
      ],
      "metadata": {
        "id": "w-ud_Q60QImr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_peptide_arrays = []\n",
        "peptide_keys = []\n",
        "all_gpcr_arrays = []\n",
        "gpcr_keys = []\n",
        "for hdf in hdfs2:\n",
        "    with h5py.File(hdf, \"r\") as f:\n",
        "        arrays = []\n",
        "        keys = list(f.keys())\n",
        "        for k in keys:\n",
        "            arrays.append(f[k][()])\n",
        "        if \"_pep_T\" in hdf:\n",
        "            all_peptide_arrays.append(arrays)\n",
        "            peptide_keys.append(keys)\n",
        "        if \"_gpcr_T\" in hdf:\n",
        "            all_gpcr_arrays.append(arrays)\n",
        "            gpcr_keys.append(keys)"
      ],
      "metadata": {
        "id": "kVE72tgzQL9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_map_gpcr = dict()\n",
        "for keys, arrays in zip(gpcr_keys, all_gpcr_arrays):\n",
        "    try:\n",
        "        gpcr = keys[0].split('_')[0]\n",
        "        for i,array in enumerate(arrays):\n",
        "            peptide = keys[i].split('_')[1]\n",
        "            emb_map_gpcr[gpcr+'_'+peptide] = array\n",
        "    except:\n",
        "        print('GPCR embedding error')\n",
        "        continue"
      ],
      "metadata": {
        "id": "P4P9Ux-kQZO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_map_peptide = dict()\n",
        "for keys, arrays in zip(peptide_keys, all_peptide_arrays):\n",
        "    try:\n",
        "        gpcr = keys[0].split('_')[0]\n",
        "        for i,array in enumerate(arrays):\n",
        "            peptide = keys[i].split('_')[1]\n",
        "            emb_map_peptide[gpcr+'_'+peptide] = array\n",
        "    except:\n",
        "        print('peptide embedding error')\n",
        "        continue"
      ],
      "metadata": {
        "id": "JcGGQzK8Qcjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embst = pd.DataFrame({'gpcr_keys': [kk for k in gpcr_keys for kk in k ], 'gpcr_embedding': [aa.mean(axis=0) for a in all_gpcr_arrays for aa in a ], 'peptide_keys': [kk for k in peptide_keys for kk in k], 'peptide_embedding': [aa.mean(axis=0) for a in all_peptide_arrays for aa in a]})"
      ],
      "metadata": {
        "id": "FyRx2UX-Qg-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embst['peptide'] = embst['peptide_keys'].apply(lambda x: x.split('_')[1])\n",
        "embst['gpcr'] = embst['gpcr_keys'].apply(lambda x: x.split('_')[0])"
      ],
      "metadata": {
        "id": "h0kYLyLHQjTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for_classification = pd.merge(left=gpcr_hits, right=embst, how='inner', left_on=['gpcr', 'peptide'], right_on=['gpcr', 'peptide'])"
      ],
      "metadata": {
        "id": "ecz7WElsQmmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcrweight = 1/gpcr_hits.groupby(['gpcr']).agg({'y': 'sum'}).sort_values(by='y')"
      ],
      "metadata": {
        "id": "M_myV9blQpfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subgraphing = True\n",
        "subgraph_hops = 1\n",
        "\n",
        "with_edge_weights = True\n",
        "\n",
        "missed = []\n",
        "all_graphs = []\n",
        "for index, g in gpcr_hits.iterrows():\n",
        "    pdb = pdb_frames[g['path']].copy()\n",
        "    if g['path'] not in interactions:\n",
        "        missed.append((mapkey, g['y']))\n",
        "        continue\n",
        "\n",
        "    mapkey = g['gpcr']+'_'+g['peptide']\n",
        "    gpcr_len = g['gpcr_len']\n",
        "\n",
        "    h_edge_index = gpcr_hits_interaction_edges[g['gpcr']+'_'+g['peptide']]\n",
        "\n",
        "    xg = emb_map_gpcr[g['gpcr']+'_'+g['peptide']]\n",
        "    xp = emb_map_peptide[g['gpcr']+'_'+g['peptide']]\n",
        "\n",
        "    x = np.concatenate([xg, xp])\n",
        "\n",
        "    x = torch.from_numpy(x).type(torch.float32)\n",
        "\n",
        "    pep_edge_index = np.vstack([np.array(range(g['gpcr_len'], len(x)-1)), np.array(range(g['gpcr_len']+1, len(x)))])\n",
        "\n",
        "    edge_index = torch.cat([torch.from_numpy(h_edge_index), torch.from_numpy(pep_edge_index)], dim=1)\n",
        "\n",
        "    if with_edge_weights:\n",
        "        if mapkey not in emb_map_interaction:\n",
        "            missed.append((mapkey, g['y']))\n",
        "            continue\n",
        "        edgefeatures = emb_map_interaction[mapkey]\n",
        "        edgeindices = emb_map_interaction_gpcrindex[mapkey]\n",
        "\n",
        "        sources = npi.remap(h_edge_index[0], edgeindices, np.arange(len(edgeindices)))\n",
        "        targets = npi.remap(h_edge_index[1], edgeindices, np.arange(len(edgeindices)))\n",
        "        sourcewherever = np.where(sources >= gpcr_len)[0]\n",
        "        targetwherever = np.where(targets < gpcr_len)[0]\n",
        "        newsources = np.array(sources)\n",
        "        newtargets = np.array(targets)\n",
        "        newsources[sourcewherever] = targets[sourcewherever]\n",
        "        newtargets[targetwherever] = sources[targetwherever]\n",
        "        newtargets -= gpcr_len\n",
        "        edge_attrs = edgefeatures[newtargets, newsources, :]\n",
        "\n",
        "        pep_edge_attrs = np.ones(shape=(len(pep_edge_index[0]),128))*edge_attrs.mean(axis=0)\n",
        "\n",
        "        edge_attrs = torch.from_numpy(edge_attrs).type(torch.float32)\n",
        "        edge_attrs = torch.cat([edge_attrs, torch.from_numpy(pep_edge_attrs)], dim=0)\n",
        "\n",
        "    if subgraphing:\n",
        "        to_keep = torch.tensor([i for i in range(gpcr_len, len(x))])\n",
        "        nodes, edges, _, _ = torch_geometric.utils.k_hop_subgraph(to_keep, subgraph_hops, edge_index, relabel_nodes=True, num_nodes=len(x))\n",
        "        if with_edge_weights:\n",
        "            edges, new_edge_attrs = torch_geometric.utils.subgraph(nodes, edge_index, edge_attrs, relabel_nodes=True)\n",
        "            graph = Data(x=x[nodes], edge_index=edges, edge_attr=new_edge_attrs, y=torch.tensor(g['y']))\n",
        "        else:\n",
        "            graph = Data(x=x[nodes], edge_index=edges, y=torch.tensor(g['y']))\n",
        "    else:\n",
        "        graph = Data(x=x, edge_index=edge_index, y=torch.tensor(g['y']))\n",
        "\n",
        "    graph.peptide = g['peptide']\n",
        "    graph.gpcr = g['gpcr']\n",
        "    graph.gpcr_family = g['gpcr_family']\n",
        "    gpcrw = gpcrweight.loc[g['gpcr']].iloc[0]\n",
        "    all_graphs.append({'graph': graph, 'peptide':g['peptide'], 'gpcr':g['gpcr'], 'gpcr_family': g['gpcr_family'], 'y': g['y'], 'gpcrweight': gpcrw})\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fntD6xoXQ8yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, train_loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        loss = criterion(logits, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def train_weighted(model, criterion, optimizer, train_loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        loss = criterion(logits, data.y)\n",
        "        loss = (loss*data.gpcrweight).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_roc(model, criterion, loader):\n",
        "     model.eval()\n",
        "     aucs = 0\n",
        "     total = len(loader.dataset)\n",
        "     correct = 0\n",
        "     for data in loader:\n",
        "         out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "         aucs += roc_auc_score(data.y.detach().cpu(), torch.softmax(out.detach(),dim=1).cpu()[:, 1])*(len(out)/total)\n",
        "     return aucs\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_without_crash(model, criterion, loader):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    atrues = []\n",
        "    for data in loader:\n",
        "        logits = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        all_logits.append(logits.cpu().detach()[:,1])\n",
        "        atrues.append(data.y.cpu())\n",
        "    return roc_auc_score(np.concatenate(atrues), np.concatenate(all_logits))\n",
        "\n",
        "@torch.no_grad()\n",
        "def nope_test_without_crash(model, criterion, loader):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    atrues = []\n",
        "    for data in loader:\n",
        "        logits = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        all_logits.append(torch.sigmoid(logits.squeeze()).cpu().detach())\n",
        "        atrues.append(data.y.cpu())\n",
        "    return roc_auc_score(np.concatenate(atrues), np.concatenate(all_logits))\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, criterion, loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_correct = 0\n",
        "    for data in loader:\n",
        "        logits = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        pred = logits.argmax(dim=-1)\n",
        "        total_correct += int((pred == data.y).sum())\n",
        "\n",
        "    return total_correct / len(test_loader.dataset)"
      ],
      "metadata": {
        "id": "4z3Nw67bUJVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_to_cuda(g):\n",
        "    g.x = g.x.cuda()\n",
        "    g.edge_index = g.edge_index.cuda()\n",
        "    g.edge_attr = g.edge_attr.cuda().type(torch.float32)\n",
        "    g.y = g.y.cuda()\n",
        "    return g"
      ],
      "metadata": {
        "id": "rYxsr5LRUfnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeorphaNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, input_channels=128, gatheads=10, gatdropout=0.5, finaldropout=0.5):\n",
        "        super(DeorphaNN, self).__init__()\n",
        "        self.finaldropout = finaldropout\n",
        "        torch.manual_seed(111)\n",
        "        self.norm = BatchNorm(input_channels)\n",
        "        self.conv1 = GATv2Conv(input_channels, hidden_channels, dropout=gatdropout, heads=gatheads, concat=False, edge_dim=128)\n",
        "        self.pooling = global_mean_pool\n",
        "        self.lin = Linear(hidden_channels, 2)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch, hidden=False):\n",
        "        x = self.norm(x)\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = x.relu()\n",
        "\n",
        "        if hidden:\n",
        "            return x\n",
        "        x = self.pooling(x, batch)\n",
        "        x = F.dropout(x, p=self.finaldropout, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "o8y7DtUXUkAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpcr_hits.groupby(['gpcr']).agg({'y': 'sum'}).sort_values(by='y')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "1sqDJ4XbVrfM",
        "outputId": "8f045131-d1a6-4c31-ee9b-6b3fd05e8a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            y\n",
              "gpcr         \n",
              "DMSR-11-1   1\n",
              "NPR-33-1    1\n",
              "NPR-34-1    1\n",
              "SEB-2-1     1\n",
              "H23L24-4-1  2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-168fd5dd-bef7-41b9-821b-3f4e4aefa1a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpcr</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DMSR-11-1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NPR-33-1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NPR-34-1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SEB-2-1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H23L24-4-1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-168fd5dd-bef7-41b9-821b-3f4e4aefa1a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-168fd5dd-bef7-41b9-821b-3f4e4aefa1a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-168fd5dd-bef7-41b9-821b-3f4e4aefa1a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82ce5cee-2826-413b-b8eb-11105ec782cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82ce5cee-2826-413b-b8eb-11105ec782cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82ce5cee-2826-413b-b8eb-11105ec782cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"gpcr_hits\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"gpcr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"NPR-33-1\",\n          \"H23L24-4-1\",\n          \"NPR-34-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for g in all_graphs:\n",
        "    g['graph'].gpcrweight = torch.tensor(g['gpcrweight']).cuda()"
      ],
      "metadata": {
        "id": "WdoPau7pelC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dicts = glob.glob('/content/drive/MyDrive/gpcrpeptidedesign/pretrainedmodels/*')"
      ],
      "metadata": {
        "id": "rcoy8gIE8kDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.load(model_state_dicts[0], weights_only=True)"
      ],
      "metadata": {
        "id": "SO1YCorE-5-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "for state in model_state_dicts:\n",
        "    weight = torch.load(state, weights_only=True)\n",
        "    units = weight['lin.weight'].shape[1]\n",
        "    print(units)\n",
        "    model = DeorphaNN(units)\n",
        "    model.load_state_dict(torch.load(state, weights_only=True))\n",
        "    models.append(model.cuda().eval())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SLoHRMF-8fL",
        "outputId": "ca3248e0-ce09-488e-bbbb-e447e5eeed5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n",
            "73\n",
            "72\n",
            "66\n",
            "50\n",
            "84\n",
            "51\n",
            "71\n",
            "66\n",
            "73\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "53\n",
            "73\n",
            "72\n",
            "66\n",
            "50\n",
            "71\n",
            "73\n",
            "52\n",
            "66\n",
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_move = []\n",
        "for graph in all_graphs:\n",
        "    to_move.append(move_to_cuda(graph['graph']))\n",
        "test_loader = DataLoader(to_move, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "PA80mQwE_AEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models[1:]:\n",
        "    print('Ensemble:')\n",
        "    test_logits = []\n",
        "    test_labels = []\n",
        "\n",
        "    candidatesgnn = []\n",
        "    hitmapgnn = []\n",
        "    average_precisions = dict()\n",
        "\n",
        "    all_logits = []\n",
        "    atrues = []\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            logits = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "            all_logits.append(logits.cpu().detach()[:,1])\n",
        "            atrues.append(data.y.cpu())\n",
        "\n",
        "    test_logits.append(np.concatenate(all_logits))\n",
        "    test_labels.append(np.concatenate(atrues))\n",
        "\n",
        "    val_gpcr = [g.gpcr for g in to_move]\n",
        "    val_peptide = [g.peptide for g in to_move]\n",
        "    result = pd.DataFrame(zip(test_labels[-1], test_logits[-1], val_gpcr, val_peptide))\n",
        "    for gpcr, r in result.groupby(2):\n",
        "        hitmapgnn.append((gpcr, r.sort_values(by=1).iloc[-17:][0].sum()))\n",
        "        candidatesgnn.append((gpcr,r.sort_values(by=1)))\n",
        "        if r[0].sum() > 0:\n",
        "            average_precisions[gpcr] = sklearn.metrics.average_precision_score(r[0], r[1])\n",
        "            print(gpcr, average_precisions[gpcr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH4_ReUaANzn",
        "outputId": "45ad28d0-8a4b-406b-f3df-401f7b133b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPCR:\n",
            "DMSR-11-1 0.005208333333333333\n",
            "H23L24-4-1 0.013081617086193745\n",
            "NPR-33-1 0.5\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.004629629629629629\n",
            "H23L24-4-1 0.1736111111111111\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.009523809523809525\n",
            "H23L24-4-1 0.29166666666666663\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.005235602094240838\n",
            "H23L24-4-1 0.29166666666666663\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.011235955056179775\n",
            "H23L24-4-1 0.04949944382647386\n",
            "NPR-33-1 0.5\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.0053475935828877\n",
            "H23L24-4-1 0.1736111111111111\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.005494505494505495\n",
            "H23L24-4-1 0.0900735294117647\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.008264462809917356\n",
            "H23L24-4-1 0.25\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.005917159763313609\n",
            "H23L24-4-1 0.24285714285714285\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.030303030303030304\n",
            "H23L24-4-1 0.5\n",
            "NPR-33-1 0.5\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.029411764705882353\n",
            "H23L24-4-1 0.4\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.038461538461538464\n",
            "H23L24-4-1 0.4\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.024390243902439025\n",
            "H23L24-4-1 0.325\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.00558659217877095\n",
            "H23L24-4-1 0.4\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.006289308176100629\n",
            "H23L24-4-1 0.325\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.037037037037037035\n",
            "H23L24-4-1 0.5\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.05555555555555555\n",
            "H23L24-4-1 0.5\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.024390243902439025\n",
            "H23L24-4-1 0.4\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.02564102564102564\n",
            "H23L24-4-1 0.4\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.022727272727272728\n",
            "H23L24-4-1 0.6666666666666666\n",
            "NPR-33-1 0.5\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.02702702702702703\n",
            "H23L24-4-1 0.5\n",
            "NPR-33-1 0.3333333333333333\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.008849557522123894\n",
            "H23L24-4-1 0.19642857142857142\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.005847953216374269\n",
            "H23L24-4-1 0.014925373134328358\n",
            "NPR-33-1 0.5\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.004739336492890996\n",
            "H23L24-4-1 0.17142857142857143\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.009433962264150943\n",
            "H23L24-4-1 0.3333333333333333\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.0047169811320754715\n",
            "H23L24-4-1 0.29166666666666663\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.005813953488372093\n",
            "H23L24-4-1 0.058823529411764705\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.007575757575757576\n",
            "H23L24-4-1 0.13333333333333333\n",
            "NPR-33-1 0.5\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.004329004329004329\n",
            "H23L24-4-1 0.25\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.008403361344537815\n",
            "H23L24-4-1 0.25\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n",
            "GPCR:\n",
            "DMSR-11-1 0.005649717514124294\n",
            "H23L24-4-1 0.2857142857142857\n",
            "NPR-33-1 1.0\n",
            "NPR-34-1 1.0\n",
            "SEB-2-1 1.0\n"
          ]
        }
      ]
    }
  ]
}