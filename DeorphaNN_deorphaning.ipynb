{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Upload the GPCR .npy file\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "uploaded_gpcr = files.upload()\n",
        "gpcr_file = list(uploaded_gpcr.keys())[0]\n",
        "gpcr_emb = np.load(gpcr_file)"
      ],
      "metadata": {
        "id": "S9WFyp7Y_9eb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload the peptide .npy file\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "uploaded_pep = files.upload()\n",
        "pep_file = list(uploaded_pep.keys())[0]\n",
        "pep_emb = np.load(pep_file)"
      ],
      "metadata": {
        "id": "18ZKVsi8BZfV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload the interaction .npy file\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "uploaded_edges = files.upload()\n",
        "edge_file = list(uploaded_edges.keys())[0]\n",
        "edge_features = np.load(edge_file)"
      ],
      "metadata": {
        "id": "jjfHLAHsBd30",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload the Arpeggio contact file (.parquet)\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "uploaded_parquet = files.upload()\n",
        "parquet_file = list(uploaded_parquet.keys())[0]\n",
        "bonds = pd.read_parquet(parquet_file)\n",
        "print(f\"Loaded {parquet_file} successfully.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8e0wB-xwGslP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "# !pip uninstall torch -y > /dev/null\n",
        "# !pip install torch==2.4.0 > /dev/null\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html > /dev/null\n",
        "!pip install torch-geometric > /dev/null\n",
        "!pip install optuna > /dev/null\n",
        "!pip install numpy-indexed > /dev/null\n",
        "import glob\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, GATv2Conv\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool\n",
        "from torch_geometric.nn import aggr\n",
        "from torch_geometric.nn.norm import GraphNorm, LayerNorm, BatchNorm\n",
        "import torch_geometric\n",
        "\n",
        "import seaborn\n",
        "import optuna\n",
        "import h5py\n",
        "import numpy_indexed as npi\n",
        "import random\n",
        "\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import subprocess as sp"
      ],
      "metadata": {
        "id": "IGXp36IT3850",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import pretrained models\n",
        "folder = \"/content/pretrained_models\"\n",
        "os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "files = [\n",
        "    \"pretrained_1.pth\",\n",
        "    \"pretrained_2.pth\",\n",
        "    \"pretrained_3.pth\",\n",
        "    \"pretrained_4.pth\",\n",
        "    \"pretrained_5.pth\",\n",
        "    \"pretrained_6.pth\",\n",
        "    \"pretrained_7.pth\",\n",
        "    \"pretrained_8.pth\",\n",
        "    \"pretrained_9.pth\",\n",
        "    \"pretrained_10.pth\"\n",
        "]\n",
        "\n",
        "base_url = \"https://huggingface.co/datasets/lariferg/DeorphaNN/resolve/main/pretrained_models/\"\n",
        "\n",
        "for fname in files:\n",
        "    path = os.path.join(folder, fname)\n",
        "    if not os.path.exists(path):\n",
        "        sp.call([\"wget\", \"-q\", \"-c\", base_url + fname, \"-P\", folder])\n",
        "\n",
        "\n",
        "\n",
        "class DeorphaNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, input_channels=128, gatheads=10, gatdropout=0.5, finaldropout=0.5):\n",
        "        super(DeorphaNN, self).__init__()\n",
        "        self.finaldropout = finaldropout\n",
        "        torch.manual_seed(111)\n",
        "        self.norm = BatchNorm(input_channels)\n",
        "        self.conv1 = GATv2Conv(input_channels, hidden_channels, dropout=gatdropout, heads=gatheads, concat=False, edge_dim=128)\n",
        "        self.pooling = global_mean_pool\n",
        "        self.lin = Linear(hidden_channels, 2)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch, hidden=False):\n",
        "        x = self.norm(x)\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = x.relu()\n",
        "\n",
        "        if hidden:\n",
        "            return x\n",
        "        x = self.pooling(x, batch)\n",
        "        x = F.dropout(x, p=self.finaldropout, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_state_dicts = glob.glob('/content/pretrained_models/*')\n",
        "weights = torch.load(model_state_dicts[0], weights_only=True)\n",
        "models = []\n",
        "for state in model_state_dicts:\n",
        "    weight = torch.load(state, weights_only=True)\n",
        "    units = weight['lin.weight'].shape[1]\n",
        "    # print(units)\n",
        "    model = DeorphaNN(units)\n",
        "    model.load_state_dict(torch.load(state, weights_only=True))\n",
        "    models.append(model.cuda().eval())"
      ],
      "metadata": {
        "id": "8KEIA2s87wSP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run DeorphaNN\n",
        "x = torch.from_numpy(np.concatenate([gpcr_emb, pep_emb])).float()\n",
        "\n",
        "\n",
        "xg = gpcr_emb\n",
        "xp = pep_emb\n",
        "x = np.concatenate([xg, xp])   # full node features\n",
        "x = torch.from_numpy(x).float()\n",
        "\n",
        "\n",
        "\n",
        "gpcr_len = xg.shape[0]  # Needed for indexing\n",
        "bonds['source'] = bonds['bgn'].apply(lambda x: x['auth_seq_id'] if x['auth_asym_id'] == \"A\" else x['auth_seq_id'] + gpcr_len) - 1\n",
        "bonds['target'] = bonds['end'].apply(lambda x: x['auth_seq_id'] if x['auth_asym_id'] == \"A\" else x['auth_seq_id'] + gpcr_len) - 1\n",
        "\n",
        "bonds = bonds.groupby(['source', 'target'])['contact'].agg(lambda x: {bondtype for array in x for bondtype in array}).reset_index()\n",
        "\n",
        "sources = bonds['source'].values\n",
        "targets = bonds['target'].values\n",
        "h_edge_index = np.vstack([sources, targets])\n",
        "\n",
        "edgeindices = np.arange(gpcr_len)\n",
        "sources = npi.remap(h_edge_index[0], edgeindices, np.arange(len(edgeindices)))\n",
        "targets = npi.remap(h_edge_index[1], edgeindices, np.arange(len(edgeindices)))\n",
        "\n",
        "sourcewherever = np.where(sources >= gpcr_len)[0]\n",
        "targetwherever = np.where(targets < gpcr_len)[0]\n",
        "\n",
        "newsources = np.array(sources)\n",
        "newtargets = np.array(targets)\n",
        "newsources[sourcewherever] = targets[sourcewherever]\n",
        "newtargets[targetwherever] = sources[targetwherever]\n",
        "\n",
        "newtargets -= gpcr_len\n",
        "edge_attrs = edge_features[newtargets, newsources, :]\n",
        "\n",
        "pep_edge_index = np.vstack([\n",
        "    np.array(range(gpcr_len, gpcr_len + xp.shape[0] - 1)),\n",
        "    np.array(range(gpcr_len + 1, gpcr_len + xp.shape[0]))\n",
        "])\n",
        "\n",
        "pep_edge_attrs = np.ones(shape=(pep_edge_index.shape[1], 128)) * edge_attrs.mean(axis=0)\n",
        "\n",
        "edge_index = np.concatenate([h_edge_index, pep_edge_index], axis=1)\n",
        "edge_index = torch.from_numpy(edge_index).long()\n",
        "\n",
        "edge_attr = torch.from_numpy(np.concatenate([edge_attrs, pep_edge_attrs], axis=0)).float()\n",
        "\n",
        "graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "\n",
        "def move_to_cuda(g):\n",
        "    g.x = g.x.cuda()\n",
        "    g.edge_index = g.edge_index.cuda()\n",
        "    g.edge_attr = g.edge_attr.cuda().type(torch.float32)\n",
        "    return g\n",
        "\n",
        "graph = move_to_cuda(graph)\n",
        "\n",
        "graph.batch = torch.zeros(graph.x.size(0), dtype=torch.long).to(graph.x.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = []\n",
        "    for i, model in enumerate(models):\n",
        "        out = model(graph.x, graph.edge_index, graph.edge_attr, graph.batch)\n",
        "        logits.append(torch.softmax(out, dim=1)[:, 1].item())\n",
        "        prob = torch.softmax(out, dim=1)[:, 1].item()\n",
        "        #print(f\"Model {i+1} predicted probability: {prob:.4f}\")\n",
        "\n",
        "    mean_prob = sum(logits) / len(logits)\n",
        "print(f\"Predicted interaction probability: {mean_prob:.4f}\")"
      ],
      "metadata": {
        "id": "FObfK32SBw1m",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}